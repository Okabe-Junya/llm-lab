# Kubernetes Style and Best Practices Guide

**Note:** This guide uses **RFC 2119** and **RFC 8174** keywords (MUST, MUST NOT, SHOULD, SHOULD NOT, MAY) to indicate the level of obligation for each rule. It is intended for mid-to-senior Kubernetes engineers writing production code, emphasizing consistency, clarity, and maintainability across large codebases.

## Environments and Namespace Isolation

- [MUST] Clearly separate **environments** (development, staging, production). Prefer using **separate clusters for production** to isolate critical workloads. If multiple environments share a cluster (to save cost or simplify admin), they MUST run in distinct namespaces with strong isolation measures ([Multi-tenancy | Kubernetes](https://kubernetes.io/docs/concepts/security/multi-tenancy/#:~:text=Sharing%20clusters%20saves%20costs%20and,fairness%2C%20and%20managing%20noisy%20neighbors)). Never deploy dev/test workloads into a prod namespace or cluster.
- [MUST] **Isolate tenants and teams**. In multi-tenant clusters, each team or project MUST have its own namespace. Enforce that no team’s processes can affect others except through well-defined APIs. This includes applying resource quotas (to prevent one tenant from hogging resources) and NetworkPolicies between namespaces ([Kubernetes Network Policies: Best Practices - Daily.dev](https://daily.dev/blog/kubernetes-network-policies-best-practices#:~:text=Kubernetes%20Network%20Policies%3A%20Best%20Practices,workloads%20remain%20isolated%20and)). Multi-tenant setups save cost but introduce security/fairness challenges, so isolation is paramount ([Multi-tenancy | Kubernetes](https://kubernetes.io/docs/concepts/security/multi-tenancy/#:~:text=Sharing%20clusters%20saves%20costs%20and,fairness%2C%20and%20managing%20noisy%20neighbors)).
- [MUST] **Label environments and owners**. Every namespace SHOULD have labels identifying its environment (e.g. `env: prod` or `env: staging`) and the owning team or business unit ([Securing Kubernetes: Using Gatekeeper to enforce effective security policies | SecureFlag](https://blog.secureflag.com/2024/03/13/security-policy-enforcement-in-kubernetes/#:~:text=alternatives%20like%20Gatekeeper%20are%20necessary,list%20a%20point%20of%20contact)). This metadata aids in management and auditing. For example, label namespaces with `owner: team-x` so it’s clear who is responsible ([Securing Kubernetes: Using Gatekeeper to enforce effective security policies | SecureFlag](https://blog.secureflag.com/2024/03/13/security-policy-enforcement-in-kubernetes/#:~:text=alternatives%20like%20Gatekeeper%20are%20necessary,list%20a%20point%20of%20contact)).
- [SHOULD] Use **consistent cluster naming** to indicate environment or region (for example, include `-prod` or `-dev` in cluster names if multiple clusters). This prevents confusion and accidents (e.g., applying a manifest to the wrong cluster).
- [MUST] Maintain **separate configurations per environment**. Configuration differences between environments (like replica counts, external service endpoints, credentials) MUST be captured via separate Helm values files or Kustomize overlays, not by manual tweaks. This ensures that promoting from staging to prod is a deliberate, tracked change.
- [SHOULD] **Test in staging before prod**. All changes (manifests or chart updates) SHOULD be applied to a staging or testing environment identical to prod before promotion. This helps catch misconfigurations early and ensures production only sees vetted changes.

## Naming and Metadata Conventions

- [MUST] **Resource names** MUST be lowercase and use hyphens `-` as separators. Follow Kubernetes naming rules (DNS label format). Names SHOULD be concise yet descriptive of their purpose or component. For example, use `payment-service-api` for a Deployment name rather than a vague name.
- [MUST] Include the application or service name in resource names to avoid collisions. If multiple environments share a cluster, include an env identifier in resource names (e.g., Deployment `payment-api-prod`) to distinguish them. If environments are isolated by namespace/cluster, you MAY omit env in the name and rely on namespace.
- [MUST] **Labels**: All Kubernetes objects MUST be labeled with key metadata: at minimum `app` or `app.kubernetes.io/name` for the application name, `env` for environment, and a `component` or `role` if applicable (e.g. `frontend`, `database`). Use the common **recommended labels** from Kubernetes where possible ([Recommended Labels | Kubernetes](https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/#:~:text=You%20can%20visualize%20and%20manage,that%20all%20tools%20can%20understand)) ([Recommended Labels | Kubernetes](https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/#:~:text=,a)). For example:
  ```yaml
  labels:
    app.kubernetes.io/name: payment-service
    app.kubernetes.io/instance: payment-service-abc123
    app.kubernetes.io/component: api
    app.kubernetes.io/version: "1.4.2"
  ```
  These standard labels provide a consistent way to identify applications across tools ([Recommended Labels | Kubernetes](https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/#:~:text=You%20can%20visualize%20and%20manage,that%20all%20tools%20can%20understand)).
- [MUST] Ensure **label selectors** match labels correctly. For instance, a Deployment’s pod template labels and the Service selecting those pods MUST match exactly. Inconsistencies will result in Services not finding pods or mis-routing traffic.
- [SHOULD] Use **annotations** for non-identifying metadata or informational tags that don’t need to be used for selection. Annotations can include things like Git commit SHA, build timestamp, contact emails, or links to runbooks. For example, annotate a Deployment with the Git commit that triggered it: `deployment.kubernetes.io/revision: abcdef1`. This information is useful for debugging and rollbacks.
- [MUST NOT] Put large or sensitive data in labels. Labels are included in etcd indexes and have size limits, so avoid storing big strings or secrets in them. Use annotations for any text that doesn’t need to be used in selectors, and never expose secrets in either (secrets belong in Secret objects).
- [SHOULD] **Consistency**: Use the same naming and labeling conventions across all manifests and teams. The style guide is enforceable – e.g., a CI linter or OPA Gatekeeper may reject manifests that don’t have required labels or that use disallowed naming patterns ([Amazon EKS Governance: Mitigating Risks and Meeting Standards using OPA Gatekeeper | by Nagababu Medicharla | Searce](https://blog.searce.com/amazon-eks-governance-mitigating-risks-and-meeting-standards-using-opa-gatekeeper-ab4f7756d351#:~:text=,Enforcing%20Pod%20Security%20Context)).

## Workloads (Deployments and Pods)

- [MUST] **Pin image versions**. All container images MUST be referenced with a specific version tag or digest. **Never use the `latest` tag** or floating tags for images in any environment. Using `latest` makes deployments non-deterministic and can lead to untracked changes. Instead, use semantic version tags or SHA256 digests (e.g., `nginx:1.21.6` or `nginx@sha256:...`).
- [MUST] **Resource requests and limits** MUST be specified for every container in every workload. This includes CPU and memory requests/limits at minimum ([Amazon EKS Governance: Mitigating Risks and Meeting Standards using OPA Gatekeeper | by Nagababu Medicharla | Searce](https://blog.searce.com/amazon-eks-governance-mitigating-risks-and-meeting-standards-using-opa-gatekeeper-ab4f7756d351#:~:text=,Enforcing%20Pod%20Security%20Context)). Defining requests/limits ensures proper scheduling, stable performance, and prevents a single pod from starving others of resources ([Securing Kubernetes: Using Gatekeeper to enforce effective security policies | SecureFlag](https://blog.secureflag.com/2024/03/13/security-policy-enforcement-in-kubernetes/#:~:text=,a%20lack%20of%20available%20resources)). For example:
  ```yaml
  resources:
    requests:
      cpu: "200m"
      memory: "256Mi"
    limits:
      cpu: "500m"
      memory: "512Mi"
  ```
  Containers without limits can consume unlimited resources and disrupt the cluster ([Securing Kubernetes: Using Gatekeeper to enforce effective security policies | SecureFlag](https://blog.secureflag.com/2024/03/13/security-policy-enforcement-in-kubernetes/#:~:text=,a%20lack%20of%20available%20resources)), so this is non-negotiable.
- [MUST] **Probes for health**: Each Deployment that runs a service MUST include a readinessProbe (to indicate when the pod is ready to serve traffic) and a livenessProbe (to detect and restart stuck processes) ([Amazon EKS Governance: Mitigating Risks and Meeting Standards using OPA Gatekeeper | by Nagababu Medicharla | Searce](https://blog.searce.com/amazon-eks-governance-mitigating-risks-and-meeting-standards-using-opa-gatekeeper-ab4f7756d351#:~:text=,Enforcing%20Pod%20Security%20Context)). Use HTTP checks for web services (e.g., an HTTP GET on `/healthz`) or TCP/command checks as appropriate. Probes ensure that Kubernetes only sends traffic to healthy pods and can self-heal unhealthy ones.
- [SHOULD] Tune probe settings carefully. Set initial delays, timeouts, and failure thresholds for livenessProbes so that they don’t cause false restarts during normal slowdowns or startup. For example, use a **startupProbe** for applications that have lengthy initialization, to delay liveness checks until startup is complete.
- [MUST] **No privileged Pods by default**. Containers MUST NOT run as privileged or with escalated capabilities unless absolutely necessary. All application pods SHOULD run as a non-root user: set `securityContext.runAsNonRoot: true` and specify a non-zero `runAsUser` UID in the container spec ([Amazon EKS Governance: Mitigating Risks and Meeting Standards using OPA Gatekeeper | by Nagababu Medicharla | Searce](https://blog.searce.com/amazon-eks-governance-mitigating-risks-and-meeting-standards-using-opa-gatekeeper-ab4f7756d351#:~:text=,Enforcing%20Pod%20Security%20Context)). For most services, also drop dangerous Linux capabilities (NET_ADMIN, SYS_ADMIN, etc.) and set `allowPrivilegeEscalation: false`. Only infrastructure pods (e.g., CNI plugins) in controlled namespaces may run privileged, and even then, they MUST be tightly reviewed.
- [MUST] **Host access**: Pods MUST NOT use `hostNetwork: true`, `hostPID: true`, or `hostIPC: true` unless absolutely required (for example, a network plugin or a monitoring agent might need hostNetwork). Similarly, avoid using `hostPort` in pod specs as it can cause port conflicts on nodes and bypasses the Kubernetes networking model ([Kubernetes with Open Policy Agent (OPA) & Gatekeeper](https://spacelift.io/blog/opa-kubernetes#:~:text=OPA%20is%20a%20tool%20that,binding%20directly%20to%20host%20ports)). If a host port is needed (e.g., for a NodePort service or daemon), document the justification and ensure only root-owned namespaces use it.
- [MUST] **Image security**: Use only trusted container images. All images SHOULD come from our approved registries or repositories ([Securing Kubernetes: Using Gatekeeper to enforce effective security policies | SecureFlag](https://blog.secureflag.com/2024/03/13/security-policy-enforcement-in-kubernetes/#:~:text=alternatives%20like%20Gatekeeper%20are%20necessary,list%20a%20point%20of%20contact)) (company registry or verified upstream sources). Unvetted images increase security risk. Additionally, **MUST NOT** use images with known vulnerabilities; incorporate image scanning in CI and keep base images updated. If using public images, pin to a digest and track updates.
- [MUST] **Multiple replicas**: Deployments for critical services MUST run at least 2 replicas (or more, depending on load) in production to avoid single points of failure. This ensures high availability during node failures or pod restarts. The only exception is stateful or singleton services that inherently cannot be replicated; those should be handled via StatefulSets and ideally also have a failover strategy.
- [SHOULD] **Pod scheduling and distribution**: For multi-replica deployments, spread pods across failure domains. Use anti-affinity rules to avoid scheduling all replicas of a service on the same node or zone. Example:
  ```yaml
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app: payment-service
  ```
  This ensures no two pods of `payment-service` end up on the same node, improving resilience.
- [SHOULD] Set an appropriate **update strategy** for Deployments. Use RollingUpdate (default) for most cases, and configure `maxUnavailable` and `maxSurge` such that capacity is maintained during rollouts. For example, for critical services you MAY set `maxUnavailable: 0` and `maxSurge: 1` to ensure no loss of serving capacity during deploys. Verify that your readiness probes and termination grace periods work together so that rolling updates do not drop traffic.
- [SHOULD] Define **Pod Disruption Budgets (PDBs)** for critical applications. A PDB ensures a minimum number of pods stay up during voluntary disruptions (like node drains or upgrades). For example, if you have 3 replicas, you might require at least 1 or 2 to always be available. This prevents Kubernetes or cluster operations from evicting too many pods at once.
- [MUST NOT] Use anti-patterns to bypass Kubernetes mechanisms. For instance, do not set overly long liveness probe intervals to mask real issues, and do not disable the deployment progress deadline on a failing rollout except during emergencies. Instead, fix underlying problems (such as pods failing to become ready). The deployment and health check settings exist to surface issues; **do not work around them in ways that hide system health**.

## Services and Ingress

- [MUST] Prefer **ClusterIP** services for internal communication. By default, create services without specifying a type (default is ClusterIP) to expose applications internally to the cluster. Use DNS (service name) for service discovery. **Do not use NodePort or LoadBalancer for internal microservice-to-microservice calls**; those are intended for external access.
- [MUST] **Service selectors**: Define a `spec.selector` in every Service that matches the intended pods’ labels. This seems obvious but is critical — a Service without a selector (or with a wrong one) will not target any pods. Ensure label keys and values match exactly with the Deployment’s pod template labels.
- [SHOULD] Use meaningful **Service naming**. E.g., use suffix `-svc` if it helps distinguish service objects, or name the service the same as the app for simplicity if unambiguous. Consistency is key. If an app has multiple services (e.g., an HTTP port and a gRPC port), name them clearly (like `myapp-http` and `myapp-grpc`).
- [MUST NOT] Expose NodePort services directly to the public internet. If NodePort is used (for example, as a target for an external load balancer or in a dev environment), it MUST be guarded by external firewall rules or limited to internal IPs. In general, NodePort and type=LoadBalancer are *cloud-provider specific* ways to get external traffic in; in production use an Ingress or cloud Gateway for controlled routing.
- [MUST] Secure all external traffic with **TLS**. All Ingress objects or external services MUST use TLS encryption for end-user traffic. For Ingress, use `spec.tls` configuration with valid certificates (managed via cert-manager or cloud integrations). For cloud LoadBalancers, terminate TLS at the LB or at the pod, but ensure certificates are in place. Plain HTTP (port 80) may be allowed only to redirect to HTTPS.
- [SHOULD] Use Kubernetes **Ingress** resources (or an API Gateway mechanism) to consolidate external HTTP(S) traffic routing rather than creating many separate LoadBalancer services. An Ingress controller (nginx, GKE Ingress, AWS ALB Ingress, etc.) can manage one or a few load balancer frontends for multiple services, reducing cost and complexity.
- [MUST] When defining Ingress rules, specify unique hostnames for each application or service. **No two services should claim the same host/path combination** in Ingress without coordination, as this causes undefined behavior. Ingress hostnames MUST be DNS names you control, and they SHOULD be globally unique (no duplicates across clusters that might conflict in DNS) ([Securing Kubernetes: Using Gatekeeper to enforce effective security policies | SecureFlag](https://blog.secureflag.com/2024/03/13/security-policy-enforcement-in-kubernetes/#:~:text=alternatives%20like%20Gatekeeper%20are%20necessary,list%20a%20point%20of%20contact)).
- [MUST] If multiple Ingress objects are used in the same namespace or cluster, define an `IngressClass` or use distinct hostnames such that each Ingress resource is clearly handled by the intended controller. For example, on EKS with an ALB Ingress controller, use the proper Ingress class annotation. On GKE, use the `kubernetes.io/ingress.class: "gce"` as needed. This prevents misrouting when multiple ingress controllers exist.
- [SHOULD] Keep Ingress rules simple and explicit. Avoid wildcard hosts or catch-all paths unless absolutely necessary, as they can inadvertently route traffic to unintended services. Instead, enumerate known hosts and paths for clarity and security.
- [SHOULD] Document any special Ingress annotations (which are often cloud-specific). For instance, GKE Ingress might use `kubernetes.io/ingress.global-static-ip-name` for static IP, and AWS ALB Ingress might use `alb.ingress.kubernetes.io/scheme` for internet-facing vs internal. Such annotations SHOULD be set via environment-specific values (Helm) or overlays so that switching cloud or environment is easy.
- [MUST] Implement **NetworkPolicies** for services, especially in a multi-tenant cluster or for security-sensitive apps. By default, Kubernetes allows all pod-to-pod communication. You SHOULD create NetworkPolicy objects to restrict traffic to only what is needed (e.g., allow your frontend pods to talk to backend pods on specific ports, and block all other access). In multi-tenant scenarios, network policies MUST isolate namespaces so that one team’s pods cannot access another’s ([Kubernetes Network Policies: Best Practices - Daily.dev](https://daily.dev/blog/kubernetes-network-policies-best-practices#:~:text=Kubernetes%20Network%20Policies%3A%20Best%20Practices,workloads%20remain%20isolated%20and)). Start with a “deny all” baseline and open required ports between the appropriate labels as needed.
- [MUST] Verify service discovery and connectivity. After deploying a Service and backing pods, ensure you can resolve the service DNS (e.g., `ping myservice.namespace.svc.cluster.local` from another pod) and that traffic flows as expected. Incorporate such checks into your deployment verification process to catch issues with selectors or network policies early.
- [SHOULD] For cluster-internal communication that needs to bypass normal service routing (for example, stateful sets with stable network IDs, or headless services for database discovery), document why and how headless services (`clusterIP: None`) or direct pod addressing is used. These are advanced use-cases; the default should be to use ClusterIP services and not rely on pod IPs directly.

## Configuration and Secrets

- [MUST] **Separate configuration from code**. Use ConfigMaps for non-sensitive configuration (feature flags, config files, etc.) and Secrets for sensitive data (credentials, keys) instead of baking these into container images or deployment manifests ([Good practices for Kubernetes Secrets | Kubernetes](https://kubernetes.io/docs/concepts/security/secrets-good-practices/#:~:text=A%20Pod%20%20can%20reference,confidential%20data)). This follows the twelve-factor app principles and allows changing config without rebuilding images.
- [MUST] **Do not commit secrets in plain text**. Kubernetes Secrets are base64-encoded by default (not true encryption), so storing the Secret manifest in Git is essentially storing the secret. Instead, you MUST use a method to encrypt or manage secrets externally in GitOps workflows. Acceptable approaches include: using sealed-secrets (encrypt secrets with a key such that only cluster can decrypt) or external secrets integration (pulling secrets from Vault/AWS Secrets Manager, etc.). **No secret material (passwords, API keys, certificates)** should appear unencrypted in Git or YAML.
- [MUST] Enable **encryption at rest** for secrets in the cluster etcd wherever the cloud provider or Kubernetes allows it ([Good practices for Kubernetes Secrets | Kubernetes](https://kubernetes.io/docs/concepts/security/secrets-good-practices/#:~:text=Secrets%20give%20you%20more%20control,to%20be%20encrypted%20at%20rest)). On GKE/EKS, turn on secret encryption with a KMS key. This ensures that if someone gets access to etcd or backups, the secrets are not trivially readable.
- [SHOULD] **Restrict Secret access by RBAC**. Kubernetes does not automatically restrict Secrets to the pods that use them – by default, a user with read access to a namespace could read all Secrets there. You SHOULD create fine-grained RBAC rules so that only privileged accounts (or controllers) can read secrets, and service accounts running your workloads do not have direct Secret access unless necessary ([Good practices for Kubernetes Secrets | Kubernetes](https://kubernetes.io/docs/concepts/security/secrets-good-practices/#:~:text=The%20following%20good%20practices%20are,more%20effectively%20manage%20your%20Secrets)). For example, if using external secrets operator, you might allow it to read certain secrets, but application pods typically just consume secrets via mounting and don’t need list/get access on the Secret object.
- [SHOULD] **Use env vars or volumes for injecting config**. Mount ConfigMaps and Secrets as files or map them to environment variables in your Pod spec. Avoid hardcoding config values in the Pod spec. This makes config changes as simple as updating the ConfigMap/Secret and redeploying (Kubernetes will roll pods when mounted ConfigMaps/Secrets change if configured, or you may trigger a rollout manually).
- [MUST] **Secrets and ConfigMaps naming**: Name Secrets and ConfigMaps with the application and purpose. e.g., `myapp-config` for general config, `myapp-db-creds` for a DB credentials secret. This makes it obvious what each contains. Also use labels on these resources (`app: myapp` and `type: config` or `type: secret`) for easier management and scanning of what’s present in a namespace.
- [SHOULD] Validate configuration at startup. When your application starts, it SHOULD verify that required config env vars or files are present (and fail fast if not). This way, a misconfigured ConfigMap/Secret will lead to a clear error and the readiness probe will keep the pod out of service. Combine this with liveness probes to automatically restart pods that fail due to bad config after you correct the issue.
- [SHOULD] For complex configuration, template the config files. You can store templates in ConfigMaps and render them with environment-specific values (via Helm or your entrypoint script). However, try to keep config simple; wherever possible, use primitive values (strings, numbers) in ConfigMaps and let the app handle them, rather than injecting entire bespoke config file templates unless absolutely needed.
- [MUST] **Rotate credentials**. This is more of an operational security practice, but it’s worth noting: any Secret (like database passwords, API tokens) should be rotated periodically and updated in the cluster. The deployment process should be able to handle secret rotation (e.g., load new secret, update pods to pick it up). Ensure that multiple versions can coexist during rotation if necessary (old and new secret) to enable a smooth transition.

## Resource Management & Cost Optimization

- [MUST] **Define CPU/Mem requests and limits for all containers** (restating for emphasis) ([Amazon EKS Governance: Mitigating Risks and Meeting Standards using OPA Gatekeeper | by Nagababu Medicharla | Searce](https://blog.searce.com/amazon-eks-governance-mitigating-risks-and-meeting-standards-using-opa-gatekeeper-ab4f7756d351#:~:text=,Enforcing%20Pod%20Security%20Context)). This is both a reliability and a cost issue: it ensures the scheduler can efficiently bin-pack pods on nodes and that one runaway container can’t consume all CPU/Memory on a node and affect others ([Securing Kubernetes: Using Gatekeeper to enforce effective security policies | SecureFlag](https://blog.secureflag.com/2024/03/13/security-policy-enforcement-in-kubernetes/#:~:text=,a%20lack%20of%20available%20resources)). Every Deployment/StatefulSet spec MUST include resources. If omitted, it will be caught in code review or CI.
- [SHOULD] **Right-size your requests**. Set resource requests to reflect the realistic lower-bound usage of the app and limits to an upper-bound that avoids malfunction. For example, if an app uses ~200m CPU and 300Mi memory under normal load, you might request that, and set limits at say 400m CPU, 500Mi memory to allow some burst but cap extreme cases. Overly large requests waste cluster capacity (leading to higher cost), while no headroom in limits might cause OOM kills if the app spikes. Monitor actual usage and adjust accordingly over time ([6 Kubernetes cost control strategies you need in place for 2023](https://www.cncf.io/blog/2023/01/10/6-kubernetes-cost-control-strategies-you-need-in-place-for-2023/#:~:text=2023%20www,Cloud%20billing)).
- [SHOULD] Use **LimitRange** and **ResourceQuota** policies. Define a `LimitRange` in each namespace to enforce default resource requests/limits on pods that don’t specify them (as a safety net) and to optionally cap how large a single resource limit can go (preventing a pod from requesting absurd resources). Use `ResourceQuota` to control the total resource usage per namespace (e.g., a team’s dev namespace may be quota-limited to 10 CPUs and 20Gi memory total). This prevents one team or app from consuming all cluster resources and encourages cost accountability.
- [SHOULD] Enable **Horizontal Pod Autoscaling (HPA)** for workloads with variable demand. HPAs SHOULD be configured to scale your Deployments based on CPU, memory, or custom metrics (like request QPS, latency, etc.). This allows the cluster to add pods when load increases and remove them when it decreases, optimizing resource usage and cost. Ensure that you have metrics-server and/or Prometheus feeding metrics for HPA to use.
- [MUST] If using HPA, ensure the cluster has the **Cluster Autoscaler** (or equivalent) running. HPA scales pods up, but if nodes are full, you need the cluster to scale out as well. On cloud providers, use managed autoscaling groups (AWS) or node auto-provisioning (GKE) such that new nodes are added when pending pods cannot be scheduled. Conversely, enable scale-in to remove idle nodes (with consideration for PodDisruptionBudgets to not violate availability). This synergy between HPA and cluster autoscaling is key to handling bursts efficiently and saving cost during troughs.
- [SHOULD] Utilize **Pod Priority Classes** for cost-effective preemption. For example, you can run non-critical batch jobs with a lower priority and allow them to be preempted when higher priority (user-facing) workloads need the resources. This way you maximize utilization: the cluster can be kept busy with low-priority tasks that yield if necessary.
- [MAY] Consider **Vertical Pod Autoscaler (VPA)** in recommendation mode to adjust your requests over time. VPA can suggest updated CPU/memory requests based on historical usage. If you choose to auto-apply it, be cautious as it can cause pod restarts when it updates requests. Often teams run VPA in “auto” for non-critical workloads or in observe mode for critical ones, and then manually adjust values.
- [MUST] **Cleanup unused resources**. Define processes or use tools to detect unused Kubernetes resources (dangling PersistentVolumes, old LoadBalancer IPs, unused CPU capacity from old deployments) and remove or downsize them. Orphaned resources (like a Service with no pods, or a volume from a deleted app) should be deleted to avoid ongoing costs.
- [SHOULD] **Optimize node sizing and scheduling**. Pack smaller pods on shared nodes and consider node pools for particular workloads. For example, memory-intensive workloads on memory-optimized nodes, or running GPU workloads on GPU node pools only. This ensures you’re not paying for resources you don’t use (e.g., CPU-bound apps running on a memory-heavy node type might waste memory). On cloud, choose a mix of instance sizes to accommodate various pod sizes.
- [SHOULD] **Leverage spot instances or preemptibles for non-critical work**. If using a cloud provider, you MAY use cheaper spot VMs for development, testing, or batch jobs that can tolerate interruption. Use taints/tolerations or separate node groups for spot instances to ensure critical workloads stay on on-demand instances. This can significantly cut cost for suitable workloads.
- [MUST] Continuously **monitor costs**. Utilize tooling like Kubecost, CloudZero, or cloud provider cost reports to break down cost by namespace/label. Track the cost of each environment and team, and use this data to optimize (e.g., if a dev cluster is idle overnight, consider shutting it down or scaling it to 0 nodes during off hours). Cost optimization is an ongoing process: set budgets or alerts if possible to catch unexpected spend.
- [MUST] **Review resource allocations regularly**. At least each sprint or month, review if any app is over-allocated (low usage but high requests) or under-allocated (frequently throttling or OOM). Adjust limits accordingly, or plan to scale that service differently. Keeping resources aligned with actual needs ensures stability and avoids waste ([6 Kubernetes cost control strategies you need in place for 2023](https://www.cncf.io/blog/2023/01/10/6-kubernetes-cost-control-strategies-you-need-in-place-for-2023/#:~:text=2023%20www,Cloud%20billing)).
- [MUST NOT] Trade reliability for cost without approval. For example, do not remove all limits to cram more pods on a node (risking instability), and do not disable important redundancy (like running single replica) just to save money in production. Cost optimizations SHOULD NOT violate the core reliability and security principles outlined in this guide.

## Security and Isolation

- [MUST] **Pod Security Standards (PSS)**: Adhere to Kubernetes Pod Security Standards at the cluster level. PodSecurityPolicies (PSP) have been removed in Kubernetes 1.25 ([Securing Kubernetes: Using Gatekeeper to enforce effective security policies | SecureFlag](https://blog.secureflag.com/2024/03/13/security-policy-enforcement-in-kubernetes/#:~:text=like%20Gatekeeper%20and%20secure%20code,techniques%20within%20your%20security%20framework)), so use the built-in Pod Security Admission controller or an equivalent to enforce at least the **Baseline** policy on all namespaces, and the **Restricted** policy on production namespaces where possible. This means pods are prevented from running as privileged, using host namespaces, etc., by default. Workloads should be built to comply with these standards (no root user, no dangerous mounts) unless there is a critical exception.
- [MUST] **No privilege escalation**: All application pods MUST run with `securityContext.allowPrivilegeEscalation: false` (which is default if no extra capabilities are added). This, combined with not running as root, ensures that even if an application is compromised, it cannot easily gain root on the node. The Restricted PSS enforcement will catch violation of this in prod clusters.
- [MUST] **Use OPA/Gatekeeper for custom policies**. For security rules and conventions not covered by Pod Security Standards, implement **policy-as-code** with Open Policy Agent (OPA) Gatekeeper. For example, you can enforce that all pods must have resource limits, all deployments must have probes, images must come from allowed registries, and that certain labels (like `owner`) are present ([Amazon EKS Governance: Mitigating Risks and Meeting Standards using OPA Gatekeeper | by Nagababu Medicharla | Searce](https://blog.searce.com/amazon-eks-governance-mitigating-risks-and-meeting-standards-using-opa-gatekeeper-ab4f7756d351#:~:text=,Enforcing%20Pod%20Security%20Context)). Gatekeeper gives a flexible way to validate such policies on every `kubectl apply`. Set up a library of policies to cover the must/should rules in this guide (e.g., reject any deployment without resource limits or without a readiness probe).
- [MUST] **Network isolation**: As mentioned in Services, apply NetworkPolicies to limit connectivity. By default, within a namespace, all pods can talk to each other; decide if that’s desired. Usually, within a microservice app, that’s fine, but cross-namespace should be restricted. **Implement a default deny policy for ingress traffic in each namespace** (except maybe a “common” namespace for shared services like ingress-controller or dns). Then explicitly allow traffic from namespace A to B only if required (e.g., allow `namespace: frontend` to talk to `namespace: backend` on port 80). This zero-trust network posture ensures a compromised pod can’t freely scan or attack others outside its scope ([Kubernetes Network Policies: Best Practices - Daily.dev](https://daily.dev/blog/kubernetes-network-policies-best-practices#:~:text=Kubernetes%20Network%20Policies%3A%20Best%20Practices,workloads%20remain%20isolated%20and)).
- [MUST] **RBAC least privilege**: Use Kubernetes Role-Based Access Control on all clusters and follow the principle of least privilege ([Best practices for GKE RBAC  |  Google Kubernetes Engine (GKE)  |  Google Cloud](https://cloud.google.com/kubernetes-engine/docs/best-practices/rbac#:~:text=Use%20the%20principle%20of%20least,privilege)). No human or service account should have more permissions than necessary. In particular:
  - Developers or CI service accounts that deploy apps SHOULD have limited access (perhaps rights to create/update resources in specific namespaces, but not cluster-wide admin).
  - Application service accounts running in pods should rarely need any RBAC roles at all (most apps don’t call the Kubernetes API). If they do (for example, an operator or an app listing pods), define a Role limited to the necessary API groups and verbs, and bind that to the specific ServiceAccount in its namespace.
  - Avoid using Kubernetes default built-in roles like cluster-admin for anything other than full cluster ops. And do **not** use the `default` service account in namespaces for running your pods – create specific service accounts so you can control permissions better and to follow good practice.
  - Regularly audit RBAC bindings: ensure no accidentally broad bindings exist (like a RoleBinding giving a service account access to secrets it shouldn’t, or a user given cluster-admin when they only need to view). Remove or tighten any overly broad permissions ([Best practices for GKE RBAC  |  Google Kubernetes Engine (GKE)  |  Google Cloud](https://cloud.google.com/kubernetes-engine/docs/best-practices/rbac#:~:text=When%20designing%20your%20roles%2C%20carefully,privilege%20escalation%20risks)).
- [MUST] **Cloud IAM integration**: When running in cloud environments (EKS, GKE, etc.), leverage cloud IAM for accessing cloud resources rather than static credentials. For AWS EKS, use IAM Roles for Service Accounts (IRSA) so that pods can assume IAM roles securely. For GKE, use Workload Identity to bind GCP service accounts to K8s service accounts. This eliminates the need to store cloud API keys in Secrets and provides fine-grained control at the pod level.
- [MUST] **Secure Kubernetes API access**: Lock down access to the Kubernetes API server. Use authentication (OIDC, etc.) integrated with company SSO for human access. Ensure that CI systems use distinct credentials (service accounts or tokens) with limited scope. Do not share Kubernetes config files or tokens in unsecured ways. Ideally, use short-lived tokens (e.g., via OIDC) or certificate auth with expiration for CI. Enforce RBAC so that even if a token is leaked, it has minimal impact.
- [SHOULD] Use **audit logs** on the API server and analyze them. This is more cluster admin side, but worth noting: ensure auditing is enabled (most managed K8s have an option for this) to track who did what. This can help in incident investigations and in verifying that all changes are via GitOps (no unexpected `kubectl exec` or `apply` outside of automation).
- [MUST] **Image security scanning**: All container images (both base images and final application images) SHOULD be scanned for vulnerabilities regularly (using tools like Trivy, Aqua, Clair, etc.). High or critical vulnerabilities MUST be addressed or mitigated before deploying to production. Additionally, enforce that only images from approved registries are deployed ([Securing Kubernetes: Using Gatekeeper to enforce effective security policies | SecureFlag](https://blog.secureflag.com/2024/03/13/security-policy-enforcement-in-kubernetes/#:~:text=alternatives%20like%20Gatekeeper%20are%20necessary,list%20a%20point%20of%20contact)) (for example, only from `our-company-registry.com` or official library images) to avoid untrusted code. This can be achieved with admission controllers or simply with policy and review.
- [SHOULD] **Regular updates and patching**: Keep the Kubernetes cluster versions and dependencies up to date (within supported versions). For workloads, update base images frequently to pick up security patches (don’t let apps run on an Alpine or Debian image from 3 years ago with known CVEs). Also update sidecar images (ingress controllers, cert managers, etc.) in a timely manner. Set a cadence (e.g., review every month or quarter) for updating these components.
- [SHOULD] **Penetration testing and threat modeling**: Periodically, conduct security reviews of your Kubernetes setup. This might include running tools to check for common misconfigurations (like kube-bench, Kube-hunter), ensuring secrets are not accessible, testing Pod Security admission is working, etc. Also, model threats like a compromised pod in namespace A – verify network policies, RBAC, etc. indeed prevent it from affecting namespace B.
- [SHOULD] **Protect node and host boundaries**: Even though this is more ops level, it intersects with our usage: ensure that the nodes themselves are hardened (use minimal base OS, apply CIS benchmarks). Do not run unnecessary packages on nodes. Use containerd (not Docker) on newer Kubernetes for smaller attack surface. Use mechanisms like NodeRestriction admission plugin so pods can’t claim to be other nodes. Where possible, use a managed node OS (like GKE’s COS or Ubuntu LTS with automatic upgrades) to reduce maintenance.
- [MUST] **Incident response readiness**: Be prepared for security incidents. For example, if a pod is compromised, have the ability to quickly revoke its credentials (maybe by rotating service account tokens or disabling its role binding), and to isolate or shut down that workload. Keep images and configs in source control to easily redeploy a clean state. Have monitoring on unusual activities (like a normally quiet namespace suddenly egressing large traffic). This is beyond pure style, but following the above practices (least privilege, network lockdown, etc.) provides layers that make incident containment easier.

## Helm Chart Best Practices

- [MUST] **Chart metadata**: Each Helm chart MUST have a proper `Chart.yaml` with `name`, `version`, `appVersion`, and description fields filled out. Follow semantic versioning for the chart `version`. The `appVersion` field should refer to the version of the application the chart deploys (useful for clarity, even though Helm itself doesn’t enforce anything with it). Update the chart version every time you make changes to the manifests or default values – do not re-use chart versions ([Securing Kubernetes: Using Gatekeeper to enforce effective security policies | SecureFlag](https://blog.secureflag.com/2024/03/13/security-policy-enforcement-in-kubernetes/#:~:text=alternatives%20like%20Gatekeeper%20are%20necessary,list%20a%20point%20of%20contact)).
- [MUST] **Values and defaults**: Provide sane default values in the `values.yaml`. A developer should be able to deploy the chart with default values (perhaps with some trivial override like an image tag) and get a running app. That means include reasonable defaults for things like resource requests (maybe small), replica count (maybe 1), etc. Do **not** assume everyone will remember to override critical things; either make them required or set a safe default. Use comments in `values.yaml` to document what each value does.
- [SHOULD] **Values structure**: Organize the values file in a logical manner. Group related values under namespaces. For example:
  ```yaml
  replicaCount: 3
  image:
    repository: nginx
    tag: 1.21.6
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 200m
      memory: 256Mi
  service:
    type: ClusterIP
    port: 80
  ```
  This structure is intuitive: image settings together, resource settings together, etc. Avoid overly nested structures that aren’t needed, as they complicate user overrides. Conversely, flat structure with dozens of top-level keys is also hard to manage – find a balance.
- [SHOULD] **Templating conventions**: Helm templates MUST produce valid Kubernetes YAML. Use the `helm lint` command to catch common mistakes. Indentation is critical in Helm templates; use the `{{- ... -}}` syntax to chomp whitespace where appropriate and `nindent` to indent multi-line blocks. For example, when including a block conditionally:
  ```yaml
  {{- if .Values.serviceAccount.create }}
  serviceAccountName: {{ include "<chartname>.fullname" . }}-sa
  {{- end }}
  ```
  Pay attention that if a value is false or empty, you don’t leave dangling punctuation in the output YAML.
- [SHOULD] **Use helpers for reuse**. If you have common template code (like computing a fullname for resource names, or common labels), define them in `_helpers.tpl`. E.g., define:
  ```yaml
  {{- define "<chartname>.labels" -}}
  app.kubernetes.io/name: {{ include "<chartname>.name" . }}
  helm.sh/chart: {{ .Chart.Name }}-{{ .Chart.Version | replace "+" "_" }}
  app.kubernetes.io/instance: {{ .Release.Name }}
  app.kubernetes.io/managed-by: {{ .Release.Service }}
  {{- end -}}
  ```
  and then include it in your Deployment, Service, etc. This ensures consistency and reduces duplication.
- [MUST] **No hard-coded environment specifics**: The chart templates SHOULD be cloud-agnostic by default. If certain fields differ between, say, GKE and EKS (like an annotation for Ingress), put those in the values (perhaps under a key like `ingress.annotations`) rather than directly in the template. Alternatively, document that the user must provide such overrides. This way the same chart can be deployed on different clouds by adjusting values, aligning with our cloud-agnostic stance.
- [SHOULD] **Chart versioning**: Bump the version appropriately: patch version for small fixes that don’t break compatibility, minor for new features or enhancements in the chart (while staying compatible), major for incompatible changes (like removing/renaming values). Team members MUST NOT deploy a chart with the same version number as an already-released chart but with different content – this causes ambiguity and should be prevented by our CI/CD (chart version uniqueness).
- [SHOULD] **Library charts and dependencies**: If you have common patterns across multiple charts (like a shared ingress or shared app deployment template), consider using Helm v3’s library chart feature or maintain a base chart that others can import. This can help enforce consistency. But use with caution – excessive abstraction can make debugging harder. Only abstract what is truly repeated and identical across services (e.g., maybe a common metrics scraper sidecar template).
- [MUST] **Avoid subchart overlap**: If using subcharts (defined in `Chart.yaml` dependencies), be aware of how values are structured for them (usually under a key of the dependency’s name). Also ensure subcharts don’t unexpectedly create resources that conflict. E.g., if two subcharts both create a ConfigMap with a fixed name, they’ll conflict when installed together in one release. Adjust names (often by including `.Release.Name` or using chart name in the resource name) to avoid such collisions.
- [SHOULD] **Helm release names**: In our GitOps setup, we often use a fixed release name for each app in a given environment (so that upgrades in place keep the same resource names). Charts should be written to work with fixed release names. Use the release name (accessible as `{{ .Release.Name }}` in templates) as part of resource naming to guarantee uniqueness when needed. For example, a Deployment name template could be:
  ```yaml
  metadata:
    name: {{ include "<chart>.fullname" . }}
  ```
  where `<chart>.fullname` might combine release name and chart name. This prevents two different releases of the same chart from clobbering each other’s resources if they accidentally land in one namespace.
- [MUST] **Document chart usage**: Include a README.md (or update the chart repository’s documentation) explaining how to use the chart, what values are configurable, and any notable design decisions. This is part of the style – ensuring others can easily pick up and use what you wrote. If using a company internal chart museum, ensure the chart is properly indexed and searchable with the documentation.
- [SHOULD] **Test your charts**: If possible, write basic tests (Helm “test” hooks or use helm unittest plugin) to verify that the rendered output is as expected given certain values. At minimum, try installing the chart in a dev cluster (or Kind) with defaults and with a representative values override file to ensure everything templates correctly. Broken Helm charts (that fail to template or produce invalid k8s resources) MUST be caught before they reach any shared repository.

## GitOps Workflow and Deployment

- [MUST] **Configuration as Code**: All Kubernetes manifests (YAML definitions), Helm release specifications, and related configuration MUST reside in Git (or a version-controlled repo). Changes to cluster config must go through Git – no ad-hoc manual changes in production. This provides history, auditability, and easy rollback ([Configuration Best Practices | Kubernetes](https://kubernetes.io/docs/concepts/configuration/overview/#:~:text=,creation%20and%20restoration)).
- [SHOULD] **Repository structure**: Organize GitOps repositories clearly. A common pattern is to have a **separate directory (or repo) for each environment** or cluster. For example, a top-level structure:
  ```text
  cluster-prod/
    namespace-a/
      app1/
        release.yaml (if using Helm releases)
        configmap.yaml
        ...
      app2/
        ...
    namespace-b/
      ...
  cluster-staging/
    ...
  ```
  Alternatively, use branches for environments (e.g., a `prod` branch and a `staging` branch). In any case, ensure that manifests for prod are isolated from dev/staging so you can protect them (e.g., prod requires more approvals).
- [MUST] **Pull Request reviews**: All changes to GitOps config MUST be done via pull requests (merge requests) and undergo review by at least one other engineer. Treat your Kubernetes config changes with the same rigor as application code changes. This helps catch mistakes (like forgetting a resource limit or adding a risky privilege) before they hit the cluster. Enable branch protection so that changes cannot be pushed directly to main or environment branches without PRs.
- [MUST] **CI validation**: The GitOps repo SHOULD have CI pipelines that validate changes. This includes **YAML linting**, **schema validation** (you can use `kubectl apply --dry-run=server` or tools like kubeval to ensure manifests are valid), and possibly policy checks (using OPA Conftest or similar) to catch policy violations early. For Helm, the CI should do a `helm template` or `helm lint` with typical values to ensure charts render. Only allow merges if these checks pass.
- [SHOULD] **Continuous deployment via GitOps**: Utilize a GitOps operator (such as Argo CD or Flux) to automatically apply changes from the Git repo to the cluster. The Git repo is the single source of truth; the operator continuously reconciles the cluster state with what’s in Git. This means when a PR is merged, the change is picked up and applied within a short time without manual kubectl. This reduces the chance of configuration drift.
- [MUST] **Drift detection**: If not using an operator that auto-syncs, you MUST at least regularly compare the live cluster state with the Git repo state (e.g., using `kubectl diff` or Argo CD in audit mode) to detect drift. **Drift** means something in the cluster doesn’t match the desired config in Git – often due to manual hotfix or an out-of-band change. Any drift should be reconciled immediately: either re-apply the Git desired state or update Git if the drift (hotfix) was necessary and should be preserved. Ideally, set up alerts for drift (Argo CD can send notifications if something is out of sync).
- [MUST] **Promotion between environments**: Define a clear process for promoting changes from dev -> staging -> prod. This could be via Git branching/merging or via automated pipelines that cherry-pick or generate PRs. For example, you might develop and test a change on a `dev` folder, then open a PR to merge that into the `staging` folder, and after staging validation, merge into `prod`. Alternatively, use tags or releases. The key is **the same artifact (container image, chart version, manifest) that was tested in staging is what goes to prod**, barring only environment-specific differences like replicas. This guarantees fidelity between stages.
- [SHOULD] **Immutable references**: In GitOps config, refer to immutable versions of artifacts. For instance, use specific image tags (not `latest`) and if using Helm releases in Git, specify exact chart versions. This way, when you promote a manifest from staging to prod, you are deploying the exact same image/chart that was just verified.
- [MUST] **Rollback strategy**: Because changes are in Git, rolling back means reverting a commit. Ensure the team knows how to do this quickly. Mark releases or use Git tags for known good states, so you can revert to a tag if needed. For example, tag the repo at `prod-v1.2.3` when you deploy version 1.2.3 of an app; if version 1.2.4 fails, you can revert the manifest to the 1.2.3 tag state.
- [SHOULD] **Gradual rollouts**: Use the GitOps pipeline to facilitate canaries or blue-green deployments if possible. For example, you might have a separate namespace or a flag in the config that allows a subset of pods to run the new version (canary). While this is more advanced, the config should accommodate such patterns rather than only all-or-nothing deploys. If an app is critical, consider strategies like Argo CD’s canary rollout (if using Argo Rollouts CRD) or manual steps documented for a blue-green cutover.
- [SHOULD] **Change logging**: Maintain a changelog of configuration changes. This can be as simple as ensuring every PR has a descriptive title and perhaps labels (like “prod change” or “hotfix”), or using conventional commits. This helps when auditing what changed in the cluster and when. For example, if an incident happened, you can trace back in Git history to see what config changes happened around that time.
- [MUST] **Access control**: Restrict who can approve/merge changes to production config. Typically, only senior engineers or SREs might have that privilege, or require multiple approvals for risky changes (like those altering network policies or cluster-level resources). This adds an extra safety net.
- [MUST] **No secrets in Git** (reiterating from secrets section): your GitOps process should handle secrets via references or encrypted files. If using SealedSecrets, those encrypted secrets *can* be in Git (since they’re safe to store). If using an external secrets operator, your Git config would contain a reference to an external secret (e.g., “fetch secret X from Vault”), which is safe. The rule is to never put actual plaintext credentials in the repo. Re-emphasizing, because a GitOps repo is often widely accessible to the team and sometimes even external systems, and secrets in it would be a severe risk.
- [MUST] **Keep GitOps repo tidy**: Remove or archive configs for applications that are no longer deployed. Remove namespaces from the config when they are decommissioned. Stale config can confuse deployments or, worse, get re-applied by automation unexpectedly. If an app is disabled, its manifests should be deleted or at least moved out of the live config directories.
- [SHOULD] **Documentation and onboarding**: Document how the GitOps process works for our team. New engineers should understand the flow: e.g., “Commit to dev branch triggers auto-deploy to dev cluster; to get to staging, open PR to staging branch; our Argo CD monitors that branch and syncs; for prod, need approval from X, then merge to prod branch.” Having this clearly written prevents misuse of the system. Also document common tasks (like “how to roll back via GitOps” or “how to emergency patch if Git or Argo is down”).

## Production Readiness & Observability

- [MUST] **Health checks**: Implement **readiness and liveness probes** for all production workloads (as noted earlier) ([Amazon EKS Governance: Mitigating Risks and Meeting Standards using OPA Gatekeeper | by Nagababu Medicharla | Searce](https://blog.searce.com/amazon-eks-governance-mitigating-risks-and-meeting-standards-using-opa-gatekeeper-ab4f7756d351#:~:text=,Enforcing%20Pod%20Security%20Context)). These are not just for Kubernetes’ benefit but also serve as **production readiness signals**. A readiness probe failing pulls the pod out of service (e.g., out of the load balancer), which is critical during deployments or if the app is struggling. A liveness probe failing triggers a restart, which can recover a hung application. Design your application with a health endpoint that checks essential dependencies (e.g., can it connect to its database? If not, perhaps report not ready) so that Kubernetes can route traffic accordingly.
- [SHOULD] **Graceful shutdown**: Your pods MUST handle SIGTERM gracefully. Kubernetes sends SIGTERM to pods during shutdown (e.g., scaling down or during a rollout) and then waits `terminationGracePeriodSeconds`. The app should catch this, start refusing new work (perhaps by toggling readiness to false), finish ongoing requests if any, and exit cleanly before the grace period. Configure `terminationGracePeriodSeconds` in your pod spec to a reasonable value (e.g., 30 seconds or more for web apps) to allow in-flight requests to complete. This prevents request loss during deployments.
- [SHOULD] **PodDisruptionBudgets**: (Reiterating from Workloads) use PDBs so that during cluster operations (node draining for maintenance) not all pods of a critical service are evicted simultaneously. This is part of being production-ready; coordinate with cluster administrators to ensure PDBs are respected during maintenance.
- [MUST] **Logging**: All applications MUST output their logs to STDOUT/STDERR (or file paths captured by sidecar agents) in a format suitable for aggregation. We have a centralized logging system (e.g., EFK stack or Cloud Logging) that collects these. Logs SHOULD be structured (JSON format or at least key-value pairs) so that they can be easily filtered and analyzed. For example, prefer logs like:
  ```json
  {"timestamp":"2025-03-27T13:45:00Z","level":"INFO","msg":"Payment processed","orderId":1234}
  ```
  over arbitrary text. This enables more powerful search queries (e.g., `orderId:1234`).
- [MUST] **No sensitive data in logs**: Developers must ensure that secrets (passwords, keys, personal data) are never logged. This can be enforced via code reviews and by scanning logs. It’s a security and compliance risk. If you absolutely must log something sensitive (rare), consider redacting or hashing it.
- [SHOULD] **Log verbosity**: Use log levels appropriately. In production, default to INFO level for normal operations, WARN for potential issues, ERROR for actual errors. DEBUG or TRACE logs should be disabled in production unless troubleshooting a specific issue, because verbose logs can both incur cost and make it harder to see important information. You SHOULD provide a way to toggle debug logging on temporarily if needed (via config) rather than keeping it always on.
- [MUST] **Monitoring & metrics**: Integrate each service with our monitoring system. At minimum, expose the standard **Kubernetes resource metrics** (CPU, memory) which the cluster monitors. But also expose **application metrics**: e.g., HTTP request rates, latencies, error counts, queue lengths, etc. Use Prometheus client libraries or other instrumentation in your app to create these metrics. Ensure a Prometheus **ServiceMonitor** or scraping annotation is in place so our Prometheus can scrape the metrics. For example, annotate your Deployment’s pods with:
  ```yaml
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
    prometheus.io/path: "/metrics"
  ```
  if using the default Prometheus scraping.
- [SHOULD] **Dashboards and alerts**: For each service, have at least a basic dashboard (showing metrics like traffic, errors, resource usage) and set up alerts for critical conditions. Some baseline alerts: high error rate (above some threshold), saturation of CPU/memory (to 90%+ of limits), pod restarts flapping, or no pods available (service down). Use alerting tools integrated with our incident management (PagerDuty, etc.) for production services. Style-wise, define SLOs (Service Level Objectives) if applicable and alert when breached (e.g., <99.9% success over last hour).
- [SHOULD] **Tracing**: Where applicable, implement **distributed tracing** (e.g., OpenTelemetry, Jaeger). This involves propagating trace IDs in requests and logging them or sending spans to a collector. Tracing is extremely helpful for debugging complex issues in microservice architectures (like pinpointing where latency is introduced). It’s a strong recommendation for production readiness, though we label it SHOULD because not all simple apps need it. If it is implemented, ensure trace sampling rate is configured (not every request, to control overhead).
- [MUST] **Backup and recovery**: For stateful components (databases, persistent volumes), have a backup strategy. E.g., if you run a database in K8s (not generally recommended for production, but if you do or for dev/test), schedule regular backups. If using persistent volumes for data, ensure either the storage class has snapshots or you have jobs to back up data to external storage. This isn’t directly in manifests, but operationally it’s critical to be production ready. Document the recovery procedure (how to restore from backup, etc.).
- [SHOULD] **Resilience testing**: Periodically perform chaos engineering or at least failure injection in non-prod environments. For example, kill pods randomly to ensure the app and Kubernetes healing can tolerate it, or simulate a node failure. This will validate that probes, replica settings, and PDBs are correctly preventing outages. Any weaknesses found should be addressed (e.g., you discover that if one pod goes down, the remaining can’t handle traffic — time to increase replica count or improve auto-scaling).
- [MUST] **High availability of critical components**: Ensure that any critical component has no single point of failure. For example, if using a StatefulSet for something like Kafka or ZooKeeper, run an odd number of replicas across different nodes (and use anti-affinity). If your application relies on an external service (like a SaaS API or database), consider what happens if that is slow or down — implement timeouts and perhaps retries or fallbacks in the code. These considerations go hand-in-hand with Kubernetes features (readiness can fail if DB is down, preventing sending traffic to an instance that can’t handle it).
- [SHOULD] **Capacity planning**: Continuously evaluate if you have enough headroom in your cluster for growth or spikes. Monitoring will show your cluster’s resource usage over time. If CPU usage is consistently above, say, 70% on average, consider adding more nodes or increasing resource quotas. Our HPA and cluster autoscaler will handle short-term bursts, but for long-term trends, plan node pool scaling or larger instance types accordingly. It’s better to scale up proactively than to constantly run at the edge of capacity.
- [MUST] **Incident response**: In the event of an incident, have runbooks ready for common issues (node failure, pod crash loops, config rollback, secret rotation, etc.). From a style perspective, an on-call engineer should be able to find relevant information quickly. This includes making sure naming/labels are clear (so one can quickly identify which deployment is which service), and that logs/metrics are easily correlatable (use consistent labels and trace IDs between services). Practicing an incident using only the information in monitoring, logs, and this config will expose if something is missing (e.g., maybe you realize an important metric isn’t being collected — add it).
